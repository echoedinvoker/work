# **_為什麼爬蟲會被擋?_**

1. **不希望多人使用同一帳號登入**，例如 **SaaS** 是依照帳號數量收費，就希望避免這種情況。
2. **希望真的人進網站才能看到廣告**，因為很多網站是藉由網站流量搭配廣告產生收益。

# **_爬蟲的嚴格定義_**

1. 依據 HTTP 的 Protocal 去跟 server request 這個網站上的 resource ，這個 resource 可能是一個 HTML 檔案(**靜態**)。
2. 然後就去**解析**這個 HTML 檔案的內容，來達到取得網頁資訊的目的。

# **_以往的爬蟲方法已經無法達到取得資料目的的原因_**

- **動態資料**的產生
  - request 到的 HTML 其實在真正的網頁中會 include 很多 **JavaScript**，很多部分都是**動態生成**，這部分就沒辦法使用以往解析靜態 HTML 檔案的方式得到。

# **_Python 套件有些可以操縱節點，模擬人為操作_**

- Python 有很多高階語法的套件可以真的去打開瀏覽器，尋找特定節點並解析其中資料
  - 比上面方法要好，但這種方法還是 follow W3C 瀏覽器的框架，通常是透過瀏覽器開放的例如 debugger 之類**測試相關的協定**去進行以上操作。
    - 瀏覽器的廠商會越來越重視使用者的**隱私權與資料的保護**，所以利用測試相關的協定可能會越來越沒有辦法達到絕大多數的功能。

# **_RPA (UiPath, AA)_**

- 利用瀏覽器提供的 **plugin 或 extension**，把它的內鬼(木馬)程式植入進去，然後就可以看到瀏覽器內的內容，並往外部送出資料。
  - plugin 無法直接達到目的，必須要有一個 **local host 當作中繼站**來接收被送出的資料。
    - 問題在於瀏覽器的 plugin 跟 local host 的搭配很容易因為 **瀏覽器版本更新**而失效，造成資料無法正常傳遞。
      - 所以 UiPath 會建議使用 robot 的 machine 最好不要去動它也不要升級瀏覽器。

# **_Emily_**

- 直接拿瀏覽器的核心 **Chromium** 來設計機器人，所以就不需要 plugin 或 extension 這些東西，所以就沒有上述隱私權或者瀏覽器更新的問題。
